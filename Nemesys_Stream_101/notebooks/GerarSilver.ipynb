{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a4474b0d-9e5b-480e-96dc-41bc53480b21",
   "metadata": {},
   "source": [
    "# Gerar Silver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ccf51d1c-cba9-4cd1-805b-24b061c375a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"PYARROW_IGNORE_TIMEZONE\"] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e45722d8-f82a-4c39-ac29-ee6dc3c70e25",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipywidgets as widgets\n",
    "import matplotlib.pyplot as plt\n",
    "import pyspark.pandas as ps\n",
    "import seaborn as sns\n",
    "\n",
    "from delta import *\n",
    "\n",
    "from matplotlib import dates\n",
    "from pyspark.sql.avro.functions import *\n",
    "from pyspark.sql.functions import col, to_date, date_format\n",
    "from pyspark.sql.types import StringType, DateType, StructType, DoubleType, IntegerType, LongType, TimestampType\n",
    "#\n",
    "# Nome da aplicação Spark\n",
    "#\n",
    "APP_NAME=\"GerarBronze\"\n",
    "ps.options.display.max_rows = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9d1179e3-e220-4206-a7cd-72bbe227da27",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run StartSpark.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f1912445-960a-48d8-bd8b-2161e83b386a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%config SqlMagic.lazy_execution = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eccbed15-f1cf-498d-b45c-a8f2ee5b0287",
   "metadata": {},
   "outputs": [],
   "source": [
    "%sql spark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b6dd65b-f67e-4c32-b8e1-584e5359385e",
   "metadata": {},
   "source": [
    "# FK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0f3484c8-1e3b-43f9-9340-e7d88d8b6c2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.parse import urlparse\n",
    "\n",
    "def delta_exists(delta_path, tier, table):\n",
    "    url = urlparse(delta_path)\n",
    "\n",
    "    match url:\n",
    "        case \"abfss\":\n",
    "            print(\"Blob Storage\")\n",
    "        case \"s3\":\n",
    "                pass\n",
    "        case \"s3a\":\n",
    "            print(\"S3 Compatible\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "adedb382-ef23-4fc9-92d9-96c3bf24ae9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.parse import urlparse\n",
    "\n",
    "def delta_exists(delta_path, tier, table):\n",
    "  \"\"\"\n",
    "  Checks if the provided delta path points to a supported storage type.\n",
    "\n",
    "  Args:\n",
    "      delta_path (str): The URL or path to the delta data.\n",
    "      tier (str): Optional tier information (may not be used).\n",
    "      table (str): Optional table name (may not be used).\n",
    "\n",
    "  Returns:\n",
    "      str: A string indicating the storage type (\"Blob Storage\" or \"S3 Compatible\")\n",
    "          or None if the storage type is not supported.\n",
    "  \"\"\"\n",
    "\n",
    "  url = urlparse(delta_path)\n",
    "  match url.scheme:\n",
    "      case \"abfss\":\n",
    "          return \"Blob Storage\"\n",
    "      case \"s3\" | \"s3a\":  # Combine S3 and S3A cases for efficiency\n",
    "          return \"S3 Compatible\"\n",
    "      case _:\n",
    "          return None  # Return None for unsupported schemes\n",
    "\n",
    "  # Unreachable code, but included for clarity\n",
    "  # return None  # Redundant return statement here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "784256cd-8491-4a4b-99da-ff3847dfa7a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def table_path(bucket:str, tier:str, table_name:str, storage:str=\"s3a\", base_dir:str=\"lakehouse\"):\n",
    "    # if len(tier.strip()) == 0:\n",
    "    #     raise ValueError(\"Tier cannot be empty\")\n",
    "\n",
    "    path = f\"{storage}://{bucket}/{base_dir}/{tier}/{table_name}\"\n",
    "    return path, path + \"/_checkpoint/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a8760935-6c4d-4656-856e-de95b4ce5d1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_bronze, stock_bronze_checkpoint_dir = table_path(\"nemesys-demo1\", \"bronze\", \"stocks_intraday\")\n",
    "stock_silver, stock_silver_checkpoint_dir = table_path(\"nemesys-demo1\", \"silver\", \"stocks_intraday\")\n",
    "stock_dup_silver = stock_silver + \"_dup\"\n",
    "stock_dup_silver_checkpoint_dir = stock_dup_silver + \"/_checkpoint/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "244d867f-a3e3-4d36-9b5b-d51d86b07584",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3a://nemesys-demo1/lakehouse/bronze/stocks_intraday s3a://nemesys-demo1/lakehouse/bronze/stocks_intraday/_checkpoint/\n",
      "s3a://nemesys-demo1/lakehouse/silver/stocks_intraday s3a://nemesys-demo1/lakehouse/silver/stocks_intraday/_checkpoint/\n",
      "s3a://nemesys-demo1/lakehouse/silver/stocks_intraday_dup s3a://nemesys-demo1/lakehouse/silver/stocks_intraday_dup/_checkpoint/\n"
     ]
    }
   ],
   "source": [
    "print(stock_bronze, stock_bronze_checkpoint_dir)\n",
    "print(stock_silver, stock_silver_checkpoint_dir)\n",
    "print(stock_dup_silver, stock_dup_silver_checkpoint_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "862671be-90d1-496f-998c-23b5e93b67e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# spark.sql(f\"\"\"\n",
    "# create table stock_intraday (\n",
    "#     ticker string,\n",
    "#     timestamp string,\n",
    "#     open double,\n",
    "#     high double,\n",
    "#     low double,\n",
    "#     close double,\n",
    "#     volume long\n",
    "# )\n",
    "# using delta location '{stock_dup_silver}'\n",
    "# \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f01629b4-9ef0-4046-b8cd-8e78b7ede74e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Criar tabela\n"
     ]
    }
   ],
   "source": [
    "if not DeltaTable.isDeltaTable(spark, stock_silver):\n",
    "    print(\"Criar tabela\")\n",
    "    schema = (StructType()\n",
    "        .add(\"ticker\", StringType())\n",
    "        .add('ano', IntegerType())\n",
    "        .add(\"timestamp\", TimestampType())\n",
    "        .add(\"open\", DoubleType())\n",
    "        .add(\"high\", DoubleType())\n",
    "        .add(\"low\", DoubleType())\n",
    "        .add(\"close\", DoubleType())\n",
    "        .add(\"volume\", LongType())\n",
    "        .add(\"_capture_time\", TimestampType())\n",
    "    )\n",
    "    emptyDF = spark.createDataFrame(spark.sparkContext.emptyRDD(), schema)\n",
    "    emptyDF.write.format('delta').mode('overwrite').partitionBy(\"ticker\", \"ano\").save(stock_silver)\n",
    "\n",
    "deltaTable = DeltaTable.forPath(spark, stock_silver)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d3a9ebd0-6ee4-462c-a29b-b65bf6d9c022",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 9.53 ms, sys: 1.6 ms, total: 11.1 ms\n",
      "Wall time: 12.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "(spark\n",
    "    .readStream\n",
    "    .format(\"delta\")\n",
    "    .option('startingOffsets', 'earliest')\n",
    "    .load(stock_bronze)\n",
    "    .writeStream\n",
    "    .format('delta')\n",
    "    .outputMode('append')\n",
    "    .option('mergeSchema', 'true')\n",
    "    .option('checkpointLocation', stock_bronze_checkpoint_dir + \"silver_dup\")\n",
    "    .trigger(once=True)\n",
    "    .start(stock_dup_silver)\n",
    "    .awaitTermination()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b865da52-e10d-47e7-8a60-876bc5261882",
   "metadata": {},
   "outputs": [],
   "source": [
    "def config_upsert(delta):\n",
    "    def upsertToDelta(microbatchdf, batchId):\n",
    "        print(f'Batch {batchId} com {microbatchdf.count()} linhas')\n",
    "        # Verificar e remover duplicatas no microbatch\n",
    "        microbatchdf_clean = microbatchdf.dropDuplicates([\"ticker\", \"timestamp\"])\n",
    "        \n",
    "        # Garantir que os campos estejam no mesmo formato\n",
    "        microbatchdf_clean = microbatchdf_clean.withColumn(\"ticker\", col(\"ticker\").cast(\"string\"))\n",
    "        microbatchdf_clean = microbatchdf_clean.withColumn(\"timestamp\", col(\"timestamp\").cast(\"timestamp\"))\n",
    "        \n",
    "        delta.alias(\"t\").merge(\n",
    "          microbatchdf_clean.alias(\"s\"),\n",
    "          \"s.ticker = t.ticker and s.timestamp = t.timestamp\") \\\n",
    "        .whenMatchedUpdateAll() \\\n",
    "        .whenNotMatchedInsertAll() \\\n",
    "        .execute()\n",
    "        print(f'Exportadas {microbatchdf_clean.count()} linhas')\n",
    "        \n",
    "    return upsertToDelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2abb210b-e1db-495a-926a-778521192816",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 0 com 0 linhas\n",
      "Exportadas 0 linhas\n",
      "CPU times: user 22.4 ms, sys: 4.09 ms, total: 26.5 ms\n",
      "Wall time: 11.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "(spark\n",
    "    .readStream\n",
    "    .format(\"delta\")\n",
    "    .option('startingOffsets', 'earliest')\n",
    "    .load(stock_bronze)\n",
    "    .withColumn('ano', date_format('timestamp', 'yyyy').cast(IntegerType()))\n",
    "    .writeStream\n",
    "    .format('delta')\n",
    "    .foreachBatch(config_upsert(deltaTable))\n",
    "    .outputMode('update')\n",
    "    .option('checkpointLocation', stock_bronze_checkpoint_dir + \"silver\")\n",
    "    .trigger(once=True)\n",
    "    .start()\n",
    "    .awaitTermination()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdfe9fa5-a00e-4cb3-88d8-4809e47b3da2",
   "metadata": {},
   "source": [
    "## Avaliar processo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "505ddcbe-0aff-497b-a72d-22745793382a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.format(\"delta\").load(stock_silver)\n",
    "df_dup = spark.read.format(\"delta\").load(stock_dup_silver)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c9059841-f2e4-4458-a4ca-cd964f184e1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.65 ms, sys: 479 µs, total: 2.13 ms\n",
      "Wall time: 688 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "87775212-5acf-4a8a-a55a-be7f0e994875",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.67 ms, sys: 483 µs, total: 2.15 ms\n",
      "Wall time: 2.26 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "df_dup.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "987f73e5-527a-4251-939b-d0b8119aed63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.03 ms, sys: 586 µs, total: 2.62 ms\n",
      "Wall time: 491 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "df.dropDuplicates([\"ticker\", \"timestamp\"]).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ac25b15b-b7ef-44ee-b0b2-42cbfe6a1ce4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- ticker: string (nullable = true)\n",
      " |-- ano: integer (nullable = true)\n",
      " |-- timestamp: timestamp (nullable = true)\n",
      " |-- open: double (nullable = true)\n",
      " |-- high: double (nullable = true)\n",
      " |-- low: double (nullable = true)\n",
      " |-- close: double (nullable = true)\n",
      " |-- volume: long (nullable = true)\n",
      " |-- _capture_time: timestamp (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "732fccf2-2418-4e70-9176-d942e7dd664d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- ticker: string (nullable = true)\n",
      " |-- timestamp: string (nullable = true)\n",
      " |-- open: double (nullable = true)\n",
      " |-- high: double (nullable = true)\n",
      " |-- low: double (nullable = true)\n",
      " |-- close: double (nullable = true)\n",
      " |-- volume: long (nullable = true)\n",
      " |-- _capture_time: timestamp (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_dup.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "43c647cc-ad07-4dcb-a894-576e7dc065df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 12.5 ms, sys: 2.98 ms, total: 15.5 ms\n",
      "Wall time: 76.8 ms\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ticker</th>\n",
       "      <th>ano</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>_capture_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [ticker, ano, timestamp, open, high, low, close, volume, _capture_time]\n",
       "Index: []"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "df.where(\"timestamp > '2024-06-01T10:30:00-03:00'\").sort(\"ticker\",\"timestamp\").pandas_api()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5b89d45-fb9e-4ea3-9736-2df388343937",
   "metadata": {},
   "source": [
    "# Otimizar Camada Bronze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f416fd2e-7deb-4591-843b-cd6a4f7aa20d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# deltaTable = DeltaTable.forPath(spark, stock_bronze)\n",
    "# df = deltaTable.optimize().executeCompaction()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "15d26374-c531-4c51-99f6-cc869f6b4c9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "64c2c20b-646b-4b0e-a6ba-dd1875139da8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# spark.conf.set(\"spark.databricks.delta.retentionDurationCheck.enabled\", \"False\")\n",
    "# deltaTable.vacuum(0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
